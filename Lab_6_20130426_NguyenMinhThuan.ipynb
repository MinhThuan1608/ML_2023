{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinhThuan1608/ML_2023/blob/main/Lab_6_20130426_NguyenMinhThuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVWQ8AEyc-C",
        "outputId": "4203bdb0-fd05-4f30-d103-542b8ef755d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ml\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ml'\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsg77IBzEyo",
        "outputId": "71cf6e31-024d-47b2-981b-0565549bfbca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature:\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   algorithsm  |      accuracy      |     precision      |       recall       |         f1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.9796296296296296 | 0.9798600359684103 | 0.9797057096088334 | 0.9796248377183057 |\n",
            "|   NaiveBayes  | 0.8314814814814815 | 0.8564459331774179 | 0.8297997449295709 | 0.8292048465599453 |\n",
            "|      SVM      | 0.9814814814814815 | 0.9809298371647509 | 0.981131213173153  | 0.9809766402036082 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n",
            "Using selection feature:\n",
            "+---------------+---------------------+--------------------+--------------------+--------------------+\n",
            "|   algorithsm  |       accuracy      |     precision      |       recall       |         f1         |\n",
            "+---------------+---------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest |  0.6481481481481481 | 0.6549605877389924 | 0.6482815970665868 | 0.6495843599665376 |\n",
            "|   NaiveBayes  | 0.48703703703703705 | 0.5920077689708905 | 0.4693686618161482 | 0.4525364262401915 |\n",
            "|      SVM      |  0.6129629629629629 | 0.6056248315239705 | 0.5964790199492207 | 0.5859804627986069 |\n",
            "+---------------+---------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X = mnist.data\n",
        "Y = mnist.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred3 = clf.predict(X_test)\n",
        "\n",
        "print(\"Without using selection feature:\")\n",
        "t = PrettyTable(['algorithsm','accuracy','precision','recall','f1'])\n",
        "t.add_row(['Random forest', metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='macro'), metrics.recall_score(y_test, y_pred, average='macro'), metrics.f1_score(y_test, y_pred, average='macro')])\n",
        "t.add_row(['NaiveBayes', metrics.accuracy_score(y_test, y_pred2),metrics.precision_score(y_test, y_pred2, average='macro'), metrics.recall_score(y_test, y_pred2, average='macro'), metrics.f1_score(y_test, y_pred2, average='macro')])\n",
        "t.add_row(['SVM', metrics.accuracy_score(y_test, y_pred3),metrics.precision_score(y_test, y_pred3, average='macro'), metrics.recall_score(y_test, y_pred3, average='macro'), metrics.f1_score(y_test, y_pred3, average='macro')])\n",
        "print(t)\n",
        "\n",
        "X = SelectKBest(chi2, k=5).fit_transform(X, Y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred3 = clf.predict(X_test)\n",
        "\n",
        "print()\n",
        "print(\"Using selection feature:\")\n",
        "t = PrettyTable(['algorithsm','accuracy','precision','recall','f1'])\n",
        "t.add_row(['Random forest', metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='macro'), metrics.recall_score(y_test, y_pred, average='macro'), metrics.f1_score(y_test, y_pred, average='macro')])\n",
        "t.add_row(['NaiveBayes', metrics.accuracy_score(y_test, y_pred2),metrics.precision_score(y_test, y_pred2, average='macro'), metrics.recall_score(y_test, y_pred2, average='macro'), metrics.f1_score(y_test, y_pred2, average='macro')])\n",
        "t.add_row(['SVM', metrics.accuracy_score(y_test, y_pred3),metrics.precision_score(y_test, y_pred3, average='macro'), metrics.recall_score(y_test, y_pred3, average='macro'), metrics.f1_score(y_test, y_pred3, average='macro')])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52OPWPD2afi"
      },
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89LEvT7dqaZ"
      },
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vx3mfIidu4P",
        "outputId": "395500af-aeba-4fa9-98a0-6ba7fb7b0a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age          job  marital  education default   balance housing  \\\n",
            "0      1.491505       admin.  married  secondary      no  0.252525     yes   \n",
            "1      1.239676       admin.  married  secondary      no -0.459974      no   \n",
            "2     -0.019470   technician  married  secondary      no -0.080160     yes   \n",
            "3      1.155733     services  married  secondary      no  0.293762     yes   \n",
            "4      1.071790       admin.  married   tertiary      no -0.416876      no   \n",
            "...         ...          ...      ...        ...     ...       ...     ...   \n",
            "11157 -0.691015  blue-collar   single    primary      no -0.473616     yes   \n",
            "11158 -0.187357     services  married  secondary      no -0.246658      no   \n",
            "11159 -0.774958   technician   single  secondary      no -0.464934      no   \n",
            "11160  0.148416   technician  married  secondary      no -0.473926      no   \n",
            "11161 -0.607072   technician  married  secondary      no -0.473926      no   \n",
            "\n",
            "      loan   contact       day month  duration  campaign     pdays  previous  \\\n",
            "0       no   unknown -1.265746   may      1042 -0.554168 -0.481184 -0.363260   \n",
            "1       no   unknown -1.265746   may      1467 -0.554168 -0.481184 -0.363260   \n",
            "2       no   unknown -1.265746   may      1389 -0.554168 -0.481184 -0.363260   \n",
            "3       no   unknown -1.265746   may       579 -0.554168 -0.481184 -0.363260   \n",
            "4       no   unknown -1.265746   may       673 -0.186785 -0.481184 -0.363260   \n",
            "...    ...       ...       ...   ...       ...       ...       ...       ...   \n",
            "11157   no  cellular  0.515650   apr       257 -0.554168 -0.481184 -0.363260   \n",
            "11158   no   unknown  0.040612   jun        83  0.547981 -0.481184 -0.363260   \n",
            "11159   no  cellular  0.396891   aug       156 -0.186785 -0.481184 -0.363260   \n",
            "11160  yes  cellular -0.909466   may         9 -0.186785  1.109571  1.818332   \n",
            "11161   no  cellular -0.790707   jul       628 -0.554168 -0.481184 -0.363260   \n",
            "\n",
            "      poutcome deposit  \n",
            "0      unknown     yes  \n",
            "1      unknown     yes  \n",
            "2      unknown     yes  \n",
            "3      unknown     yes  \n",
            "4      unknown     yes  \n",
            "...        ...     ...  \n",
            "11157  unknown      no  \n",
            "11158  unknown      no  \n",
            "11159  unknown      no  \n",
            "11160  failure      no  \n",
            "11161  unknown      no  \n",
            "\n",
            "[11162 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "#code\n",
        "data = pd.read_csv(\"bank.csv\")\n",
        "\n",
        "col = data.iloc[:, 0:1]\n",
        "scaler = StandardScaler()\n",
        "data[\"age\"] = scaler.fit_transform(col)\n",
        "\n",
        "col = data.iloc[:, 5:6]\n",
        "scaler = StandardScaler()\n",
        "data[\"balance\"] = scaler.fit_transform(col)\n",
        "\n",
        "col = data.iloc[:, 9:10]\n",
        "scaler = StandardScaler()\n",
        "data[\"day\"] = scaler.fit_transform(col)\n",
        "\n",
        "col = data.iloc[:, 12:13]\n",
        "scaler = StandardScaler()\n",
        "data[\"campaign\"] = scaler.fit_transform(col)\n",
        "\n",
        "col = data.iloc[:, 13:14]\n",
        "scaler = StandardScaler()\n",
        "data[\"pdays\"] = scaler.fit_transform(col)\n",
        "\n",
        "col = data.iloc[:, 14:15]\n",
        "scaler = StandardScaler()\n",
        "data[\"previous\"] = scaler.fit_transform(col)\n",
        "\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7acR0TxdvY8"
      },
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtgBmAtd0um",
        "outputId": "deb4eb74-a204-4672-9ae8-585c871d24a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age  job  marital  education  default   balance  housing  loan  \\\n",
            "0      1.491505    0        1          1        0  0.252525        1     0   \n",
            "1      1.239676    0        1          1        0 -0.459974        0     0   \n",
            "2     -0.019470    9        1          1        0 -0.080160        1     0   \n",
            "3      1.155733    7        1          1        0  0.293762        1     0   \n",
            "4      1.071790    0        1          2        0 -0.416876        0     0   \n",
            "...         ...  ...      ...        ...      ...       ...      ...   ...   \n",
            "11157 -0.691015    1        2          0        0 -0.473616        1     0   \n",
            "11158 -0.187357    7        1          1        0 -0.246658        0     0   \n",
            "11159 -0.774958    9        2          1        0 -0.464934        0     0   \n",
            "11160  0.148416    9        1          1        0 -0.473926        0     1   \n",
            "11161 -0.607072    9        1          1        0 -0.473926        0     0   \n",
            "\n",
            "       contact       day  month  duration  campaign     pdays  previous  \\\n",
            "0            2 -1.265746      8      1042 -0.554168 -0.481184 -0.363260   \n",
            "1            2 -1.265746      8      1467 -0.554168 -0.481184 -0.363260   \n",
            "2            2 -1.265746      8      1389 -0.554168 -0.481184 -0.363260   \n",
            "3            2 -1.265746      8       579 -0.554168 -0.481184 -0.363260   \n",
            "4            2 -1.265746      8       673 -0.186785 -0.481184 -0.363260   \n",
            "...        ...       ...    ...       ...       ...       ...       ...   \n",
            "11157        0  0.515650      0       257 -0.554168 -0.481184 -0.363260   \n",
            "11158        2  0.040612      6        83  0.547981 -0.481184 -0.363260   \n",
            "11159        0  0.396891      1       156 -0.186785 -0.481184 -0.363260   \n",
            "11160        0 -0.909466      8         9 -0.186785  1.109571  1.818332   \n",
            "11161        0 -0.790707      5       628 -0.554168 -0.481184 -0.363260   \n",
            "\n",
            "       poutcome deposit  \n",
            "0             3     yes  \n",
            "1             3     yes  \n",
            "2             3     yes  \n",
            "3             3     yes  \n",
            "4             3     yes  \n",
            "...         ...     ...  \n",
            "11157         3      no  \n",
            "11158         3      no  \n",
            "11159         3      no  \n",
            "11160         0      no  \n",
            "11161         3      no  \n",
            "\n",
            "[11162 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "col = data.iloc[:, 1:2]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"job\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 2:3]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"marital\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 3:4]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"education\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 4:5]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"default\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 6:7]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"housing\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 7:8]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"loan\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 8:9]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"contact\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 10:11]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"month\"] =col.indices\n",
        "\n",
        "col = data.iloc[:, 15:16]\n",
        "col = enc.fit_transform(col)\n",
        "data[\"poutcome\"] =col.indices\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Si6d69d1nh"
      },
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouil-cf_d8jW",
        "outputId": "99fa1dbc-f197-4965-af0f-4809f7de0ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   algorithsm  |      accuracy      |     precision      |       recall       |         f1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.8462227530606151 | 0.8467801489789802 | 0.8475787015847589 | 0.8461797440661967 |\n",
            "|   NaiveBayes  | 0.7476858763810093 | 0.7564661384858623 | 0.7519637851135649 | 0.7471650487813617 |\n",
            "|      SVM      | 0.798745894296805  | 0.7982152613367328 | 0.7986172692945821 | 0.7983679173214364 |\n",
            "| Decision tree | 0.783517467900866  | 0.7830799980224226 | 0.7825388680702557 | 0.7827581150147939 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "X = data.iloc[:, 0:16]\n",
        "Y = data[\"deposit\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred3 = clf.predict(X_test)\n",
        "\n",
        "dtc = DecisionTreeClassifier(random_state=0)\n",
        "dtc.fit(X_train, y_train)\n",
        "y_pred4 = dtc.predict(X_test)\n",
        "\n",
        "t = PrettyTable(['algorithsm','accuracy','precision','recall','f1'])\n",
        "t.add_row(['Random forest', metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='macro'), metrics.recall_score(y_test, y_pred, average='macro'), metrics.f1_score(y_test, y_pred, average='macro')])\n",
        "t.add_row(['NaiveBayes', metrics.accuracy_score(y_test, y_pred2),metrics.precision_score(y_test, y_pred2, average='macro'), metrics.recall_score(y_test, y_pred2, average='macro'), metrics.f1_score(y_test, y_pred2, average='macro')])\n",
        "t.add_row(['SVM', metrics.accuracy_score(y_test, y_pred3),metrics.precision_score(y_test, y_pred3, average='macro'), metrics.recall_score(y_test, y_pred3, average='macro'), metrics.f1_score(y_test, y_pred3, average='macro')])\n",
        "t.add_row(['Decision tree', metrics.accuracy_score(y_test, y_pred4),metrics.precision_score(y_test, y_pred4, average='macro'), metrics.recall_score(y_test, y_pred4, average='macro'), metrics.f1_score(y_test, y_pred4, average='macro')])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SweVRB4meApP"
      },
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "seFBhqCSeC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81fe4de-36f8-43e2-9b17-f466a0740bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature:\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   algorithsm  |      accuracy      |     precision      |       recall       |         f1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.8462227530606151 | 0.8467801489789802 | 0.8475787015847589 | 0.8461797440661967 |\n",
            "|   NaiveBayes  | 0.7476858763810093 | 0.7564661384858623 | 0.7519637851135649 | 0.7471650487813617 |\n",
            "|      SVM      | 0.798745894296805  | 0.7982152613367328 | 0.7986172692945821 | 0.7983679173214364 |\n",
            "| Decision tree | 0.783517467900866  | 0.7830799980224226 | 0.7825388680702557 | 0.7827581150147939 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n",
            "\n",
            "Using selection feature:\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   algorithsm  |      accuracy      |     precision      |       recall       |         f1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.7645478961504029 | 0.765038172836338  | 0.7650874930217337 | 0.7645471413056981 |\n",
            "|   NaiveBayes  | 0.7054610564010743 | 0.7138969521044993 | 0.7023745355843456 | 0.7003415763393357 |\n",
            "|      SVM      | 0.7699194270367055 | 0.7699072203948423 | 0.7701150531631599 | 0.769872209569572  |\n",
            "| Decision tree | 0.7493285586392122 | 0.7500630105469961 | 0.7482899237042884 | 0.7484768356783951 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "print('Without using selection feature:')\n",
        "print(t)\n",
        "\n",
        "print()\n",
        "\n",
        "print()\n",
        "\n",
        "X = SelectKBest(f_classif, k=5).fit_transform(X, Y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.3, test_size = 0.1, random_state = 1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred3 = clf.predict(X_test)\n",
        "\n",
        "dtc = DecisionTreeClassifier(random_state=0)\n",
        "dtc.fit(X_train, y_train)\n",
        "y_pred4 = dtc.predict(X_test)\n",
        "\n",
        "t = PrettyTable(['algorithsm','accuracy','precision','recall','f1'])\n",
        "t.add_row(['Random forest', metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='macro'), metrics.recall_score(y_test, y_pred, average='macro'), metrics.f1_score(y_test, y_pred, average='macro')])\n",
        "t.add_row(['NaiveBayes', metrics.accuracy_score(y_test, y_pred2),metrics.precision_score(y_test, y_pred2, average='macro'), metrics.recall_score(y_test, y_pred2, average='macro'), metrics.f1_score(y_test, y_pred2, average='macro')])\n",
        "t.add_row(['SVM', metrics.accuracy_score(y_test, y_pred3),metrics.precision_score(y_test, y_pred3, average='macro'), metrics.recall_score(y_test, y_pred3, average='macro'), metrics.f1_score(y_test, y_pred3, average='macro')])\n",
        "t.add_row(['Decision tree', metrics.accuracy_score(y_test, y_pred4),metrics.precision_score(y_test, y_pred4, average='macro'), metrics.recall_score(y_test, y_pred4, average='macro'), metrics.f1_score(y_test, y_pred4, average='macro')])\n",
        "print('Using selection feature:')\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      },
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and then compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc97466a-7ef9-4c9a-ad41-c4c4de4ef5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     algorithsm     |      accuracy      |     precision      |       recall       |         f1         |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| LogisticRegression | 0.9996489996489997 | 0.9998243765367053 | 0.8333333333333333 | 0.8999121728438433 |\n",
            "|        kNN         | 0.9992979992979993 | 0.8331576481611618 | 0.8331576481611618 | 0.8331576481611618 |\n",
            "|   Decision tree    | 0.9985959985959986 | 0.6998241912798875 | 0.8328062778168189 | 0.7496485061511424 |\n",
            "|        SVM         | 0.9992979992979993 | 0.8331576481611618 | 0.8331576481611618 | 0.8331576481611618 |\n",
            "|   Random forest    | 0.9992979992979993 | 0.8331576481611618 | 0.8331576481611618 | 0.8331576481611618 |\n",
            "|     NaiveBayes     | 0.9936819936819937 | 0.5524549005021387 | 0.8303466854064183 | 0.589323467230444  |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "X = data.iloc[:, 1:30]\n",
        "Y = data['Class']\n",
        "X = SelectKBest(f_classif, k=5).fit_transform(X, Y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.01, train_size = 0.1, shuffle=True, random_state = 1)\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "dtc = DecisionTreeClassifier(random_state=0)\n",
        "dtc.fit(X_train, y_train)\n",
        "y_pred3 = dtc.predict(X_test)\n",
        "\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred4 = clf.predict(X_test)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred5 = clf.predict(X_test)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred6 = model.predict(X_test)\n",
        "\n",
        "t = PrettyTable(['algorithsm','accuracy','precision','recall','f1'])\n",
        "t.add_row(['LogisticRegression', metrics.accuracy_score(y_test, y_pred),metrics.precision_score(y_test, y_pred, average='macro'), metrics.recall_score(y_test, y_pred, average='macro'), metrics.f1_score(y_test, y_pred, average='macro')])\n",
        "t.add_row(['kNN', metrics.accuracy_score(y_test, y_pred2),metrics.precision_score(y_test, y_pred2, average='macro'), metrics.recall_score(y_test, y_pred2, average='macro'), metrics.f1_score(y_test, y_pred2, average='macro')])\n",
        "t.add_row(['Decision tree', metrics.accuracy_score(y_test, y_pred3),metrics.precision_score(y_test, y_pred3, average='macro'), metrics.recall_score(y_test, y_pred3, average='macro'), metrics.f1_score(y_test, y_pred3, average='macro')])\n",
        "t.add_row(['SVM', metrics.accuracy_score(y_test, y_pred4),metrics.precision_score(y_test, y_pred4, average='macro'), metrics.recall_score(y_test, y_pred4, average='macro'), metrics.f1_score(y_test, y_pred4, average='macro')])\n",
        "t.add_row(['Random forest', metrics.accuracy_score(y_test, y_pred5),metrics.precision_score(y_test, y_pred5, average='macro'), metrics.recall_score(y_test, y_pred5, average='macro'), metrics.f1_score(y_test, y_pred5, average='macro')])\n",
        "t.add_row(['NaiveBayes', metrics.accuracy_score(y_test, y_pred6),metrics.precision_score(y_test, y_pred6, average='macro'), metrics.recall_score(y_test, y_pred6, average='macro'), metrics.f1_score(y_test, y_pred6, average='macro')])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}