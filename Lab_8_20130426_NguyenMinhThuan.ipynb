{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinhThuan1608/ML_2023/blob/main/Lab_8_20130426_NguyenMinhThuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_1_1 = grid.best_params_\n",
        "best_score_1_1 = grid.best_score_\n",
        "best_index_1_1 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_1_1)\n",
        "print(\"Best score: \", best_score_1_1)\n",
        "print(\"Best index: \", best_index_1_1)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72c8038-fbfe-44c0-fba9-b3c2b2b12187"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
            "Best score:  0.9809090909090908\n",
            "Best index:  11\n",
            "y_pred:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(), grid_params, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_1_2 = grid.best_params_\n",
        "best_score_1_2 = grid.best_score_\n",
        "best_index_1_2 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_1_2)\n",
        "print(\"Best score: \", best_score_1_2)\n",
        "print(\"Best index: \", best_index_1_2)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ee7d66-46b2-43ae-d599-5e714df13abb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "Best score:  0.9709090909090909\n",
            "Best index:  5\n",
            "y_pred:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_1_3 = grid.best_params_\n",
        "best_score_1_3 = grid.best_score_\n",
        "best_index_1_3 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_1_3)\n",
        "print(\"Best score: \", best_score_1_3)\n",
        "print(\"Best index: \", best_index_1_3)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c9aba8-b1f2-45bc-e8d5-518927671db7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'n_estimators': 50}\n",
            "Best score:  0.9709090909090909\n",
            "Best index:  73\n",
            "y_pred:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to display the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "t = PrettyTable(['algorithsm','best_param','best_score','best_index'])\n",
        "t.add_row(['SVM', best_param_1_1, best_score_1_1, best_index_1_1])\n",
        "t.add_row(['kNN', best_param_1_2, best_score_1_2, best_index_1_2])\n",
        "t.add_row(['Random Forest', best_param_1_3, best_score_1_3, best_index_1_3])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ACT1jnfC_E",
        "outputId": "aae4e7c2-a258-4c69-d57a-9a7db0283b30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------------------------------------------------------------------------------+--------------------+------------+\n",
            "|   algorithsm  |                                     best_param                                    |     best_score     | best_index |\n",
            "+---------------+-----------------------------------------------------------------------------------+--------------------+------------+\n",
            "|      SVM      |                      {'C': 1, 'gamma': 1, 'kernel': 'linear'}                     | 0.9809090909090908 |     11     |\n",
            "|      kNN      |          {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}         | 0.9709090909090909 |     5      |\n",
            "| Random Forest | {'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'n_estimators': 50} | 0.9709090909090909 |     73     |\n",
            "+---------------+-----------------------------------------------------------------------------------+--------------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, train_size=0.3, random_state=1)\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_2_1 = grid.best_params_\n",
        "best_score_2_1 = grid.best_score_\n",
        "best_index_2_1 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_2_1)\n",
        "print(\"Best score: \", best_score_2_1)\n",
        "print(\"Best index: \", best_index_2_1)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0672b79c-0d89-4532-d8eb-ea27d0aa2ff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best score:  0.9411764705882353\n",
            "Best index:  16\n",
            "y_pred:  [1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(), grid_params, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_2_2 = grid.best_params_\n",
        "best_score_2_2 = grid.best_score_\n",
        "best_index_2_2 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_2_2)\n",
        "print(\"Best score: \", best_score_2_2)\n",
        "print(\"Best index: \", best_index_2_2)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320bebd9-7392-4ca4-e8ba-3936e67a3f52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "Best score:  0.9176470588235294\n",
            "Best index:  24\n",
            "y_pred:  [1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2'],\n",
        "              'solver': ['liblinear', 'saga']}\n",
        "lr = LogisticRegression(random_state=1)\n",
        "grid_search = GridSearchCV(lr, param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_param_2_3 = grid.best_params_\n",
        "best_score_2_3 = grid.best_score_\n",
        "best_index_2_3 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_2_3)\n",
        "print(\"Best score: \", best_score_2_3)\n",
        "print(\"Best index: \", best_index_2_3)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df38fb1f-f8e9-4fe3-d0e3-19b1af6bca0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "Best score:  0.9176470588235294\n",
            "Best index:  24\n",
            "y_pred:  [1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_param_2_4 = grid.best_params_\n",
        "best_score_2_4 = grid.best_score_\n",
        "best_index_2_4 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_2_4)\n",
        "print(\"Best score: \", best_score_2_4)\n",
        "print(\"Best index: \", best_index_2_4)\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a697d33c-327c-4051-d285-930fc6f5f1ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'max_depth': 9, 'max_features': 'log2', 'max_leaf_nodes': 6, 'n_estimators': 100}\n",
            "Best score:  0.9588235294117646\n",
            "Best index:  90\n",
            "y_pred:  [1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "t = PrettyTable(['algorithsm','best_param','best_score','best_index'])\n",
        "t.add_row(['SVM', best_param_2_1, best_score_2_1, best_index_2_1])\n",
        "t.add_row(['kNN', best_param_2_2, best_score_2_2, best_index_2_2])\n",
        "t.add_row(['LogisticRegression', best_param_2_3, best_score_2_3, best_index_2_3])\n",
        "t.add_row(['Random Forest', best_param_2_4, best_score_2_4, best_index_2_4])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d459137a-ec7f-4338-80c8-a1f5e717c813"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n",
            "|     algorithsm     |                                     best_param                                     |     best_score     | best_index |\n",
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n",
            "|        SVM         |                     {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}                      | 0.9411764705882353 |     16     |\n",
            "|        kNN         |          {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}           | 0.9176470588235294 |     24     |\n",
            "| LogisticRegression |          {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}           | 0.9176470588235294 |     24     |\n",
            "|   Random Forest    | {'max_depth': 9, 'max_features': 'log2', 'max_leaf_nodes': 6, 'n_estimators': 100} | 0.9588235294117646 |     90     |\n",
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225fb43f-7cb5-460f-917f-bdaa44f4125f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044ebb24-8f22-48f8-fde5-8c94221c360f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4678f3d8-59af-4683-9943-873eb1997582"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32dc2cb4-dfd3-4a06-bbce-5abcf2ac9661"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70085dae-8242-4a9c-942d-ec268630d3c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train_bow, y_train)\n",
        "\n",
        "best_param_3_6 = grid.best_params_\n",
        "best_score_3_6 = grid.best_score_\n",
        "best_index_3_6 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_3_6)\n",
        "print(\"Best score: \", best_score_3_6)\n",
        "print(\"Best index: \", best_index_3_6)\n",
        "y_pred = grid.predict(X_test_bow)\n",
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135e67c9-8e25-4270-9ffb-c080481e21a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best score:  0.858955223880597\n",
            "Best index:  22\n",
            "y_pred:  ['pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos'\n",
            " 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
            " 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
            " 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
            " 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
            " 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
            " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
            " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg'\n",
            " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
            " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
            " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
            " 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
            " 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
            " 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
            " 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
            " 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
            " 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
            " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
            " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
            " 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos'\n",
            " 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
            " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
            " 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
            " 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
            " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
            " 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
            " 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
            " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
            " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos'\n",
            " 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
            " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
            " 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
            " 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
            " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
            " 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
            " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos'\n",
            " 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
            " 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
            " 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
            " 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
            " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg'\n",
            " 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos'\n",
            " 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
            " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train_bow, y_train)\n",
        "\n",
        "best_param_3_7 = grid.best_params_\n",
        "best_score_3_7 = grid.best_score_\n",
        "best_index_3_7 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_3_7)\n",
        "print(\"Best score: \", best_score_3_7)\n",
        "print(\"Best index: \", best_index_3_7)\n",
        "y_pred = grid.predict(X_test_bow)\n"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922ee207-cc09-4eab-fc4f-9f492294feb7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 100}\n",
            "Best score:  0.8007462686567164\n",
            "Best index:  46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(), grid_params, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid.fit(X_train_bow, y_train)\n",
        "\n",
        "best_param_3_8 = grid.best_params_\n",
        "best_score_3_8 = grid.best_score_\n",
        "best_index_3_8 = grid.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_3_8)\n",
        "print(\"Best score: \", best_score_3_8)\n",
        "print(\"Best index: \", best_index_3_8)\n",
        "y_pred = grid.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb68cbb5-51dd-4fe2-cee7-4b0503f1c419"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
            "Best score:  0.6485074626865671\n",
            "Best index:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2'],\n",
        "              'solver': ['liblinear', 'saga']}\n",
        "lr = LogisticRegression(random_state=1)\n",
        "grid_search = GridSearchCV(lr, param_grid, scoring=\"accuracy\", n_jobs=4, cv=10, refit=True)\n",
        "grid_search.fit(X_train_bow, y_train)\n",
        "\n",
        "best_param_3_9 = grid_search.best_params_\n",
        "best_score_3_9 = grid_search.best_score_\n",
        "best_index_3_9 = grid_search.best_index_\n",
        "\n",
        "print(\"Best hyperparameters: \", best_param_3_9)\n",
        "print(\"Best score: \", best_score_3_9)\n",
        "print(\"Best index: \", best_index_3_9)\n",
        "y_pred = grid_search.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f937097-b3fd-4e5d-912f-9ccce7547116"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Best score:  0.8537313432835821\n",
            "Best index:  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['algorithsm','best_param','best_score','best_index'])\n",
        "t.add_row(['SVM', best_param_3_6, best_score_3_6, best_index_3_6])\n",
        "t.add_row(['Random Forest', best_param_3_7, best_score_3_7, best_index_3_7])\n",
        "t.add_row(['kNN', best_param_3_8, best_score_3_8, best_index_3_8])\n",
        "t.add_row(['LogisticRegression', best_param_3_9, best_score_3_9, best_index_3_9])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h46_IwFIP1K1",
        "outputId": "39ac8a78-6fbb-4736-b290-5bf5fbd620ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n",
            "|     algorithsm     |                                     best_param                                     |     best_score     | best_index |\n",
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n",
            "|        SVM         |                      {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}                      | 0.858955223880597  |     22     |\n",
            "|   Random Forest    | {'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 100} | 0.8007462686567164 |     46     |\n",
            "|        kNN         |         {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}          | 0.6485074626865671 |     11     |\n",
            "| LogisticRegression |                    {'C': 10, 'penalty': 'l2', 'solver': 'saga'}                    | 0.8537313432835821 |     19     |\n",
            "+--------------------+------------------------------------------------------------------------------------+--------------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}